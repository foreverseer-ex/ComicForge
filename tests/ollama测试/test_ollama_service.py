"""
Ollama ç‹¬ç«‹åŠŸèƒ½æµ‹è¯•ã€‚

ç‹¬ç«‹æµ‹è¯• Ollama SDK çš„å„é¡¹åŠŸèƒ½ï¼Œä¸ä¾èµ–é¡¹ç›®å†…éƒ¨æ¨¡å—ï¼š
- è·å–æ¨¡å‹åˆ—è¡¨ï¼ˆollama.list()ï¼‰
- è·å–æ¨¡å‹åˆ—è¡¨ï¼ˆä½¿ç”¨ Clientï¼‰
- æµ‹è¯•æ¨¡å‹å¯¹è¯
- æµ‹è¯•é”™è¯¯å¤„ç†
"""
import sys
import os
import asyncio

# è®¾ç½® UTF-8 ç¼–ç 
if sys.platform == 'win32':
    os.environ['PYTHONIOENCODING'] = 'utf-8'

import ollama
from loguru import logger


DEFAULT_OLLAMA_BASE_URL = "http://127.0.0.1:11434"


def test_get_ollama_models_direct():
    """æµ‹è¯• 1: ä½¿ç”¨ ollama.list() ç›´æ¥è·å–æ¨¡å‹åˆ—è¡¨"""
    logger.info("=" * 60)
    logger.info("æµ‹è¯• 1: ä½¿ç”¨ ollama.list() ç›´æ¥è·å–æ¨¡å‹åˆ—è¡¨")
    logger.info("=" * 60)
    
    try:
        # ä½¿ç”¨é»˜è®¤çš„ ollama.list()
        data = ollama.list()
        
        # æå–æ¨¡å‹åç§°åˆ—è¡¨
        models = []
        if hasattr(data, 'models'):
            models = [model.name for model in data.models]
        elif isinstance(data, dict):
            models = [model.get('name') for model in data.get('models', []) if model.get('name')]
        
        logger.info(f"âœ… æˆåŠŸè·å– {len(models)} ä¸ª Ollama æ¨¡å‹")
        for i, model in enumerate(models, 1):
            logger.info(f"  {i}. {model}")
        
        assert len(models) > 0, "åº”è¯¥è‡³å°‘æœ‰ä¸€ä¸ª Ollama æ¨¡å‹"
        return models
        
    except Exception as e:
        logger.error(f"âŒ è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")
        logger.error(f"   è¯·ç¡®ä¿ Ollama æœåŠ¡æ­£åœ¨è¿è¡Œï¼ˆ{DEFAULT_OLLAMA_BASE_URL}ï¼‰")
        raise


def test_get_ollama_models_with_client():
    """æµ‹è¯• 2: ä½¿ç”¨ Client(host=base_url).list() è·å–æ¨¡å‹åˆ—è¡¨"""
    logger.info("=" * 60)
    logger.info("æµ‹è¯• 2: ä½¿ç”¨ Client(host=base_url).list() è·å–æ¨¡å‹åˆ—è¡¨")
    logger.info("=" * 60)
    
    try:
        base_url = DEFAULT_OLLAMA_BASE_URL
        
        # ä½¿ç”¨ Client æŒ‡å®š host
        client = ollama.Client(host=base_url)
        data = client.list()
        
        # æå–æ¨¡å‹åç§°åˆ—è¡¨
        models = []
        if hasattr(data, 'models'):
            models = [model.name for model in data.models]
        elif isinstance(data, dict):
            models = [model.get('name') for model in data.get('models', []) if model.get('name')]
        
        logger.info(f"âœ… æˆåŠŸè·å– {len(models)} ä¸ª Ollama æ¨¡å‹ (base_url: {base_url})")
        for i, model in enumerate(models, 1):
            logger.info(f"  {i}. {model}")
        
        assert len(models) > 0, "åº”è¯¥è‡³å°‘æœ‰ä¸€ä¸ª Ollama æ¨¡å‹"
        return models
        
    except Exception as e:
        logger.error(f"âŒ è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")
        logger.error(f"   è¯·ç¡®ä¿ Ollama æœåŠ¡æ­£åœ¨è¿è¡Œï¼ˆ{base_url}ï¼‰")
        raise


def test_get_ollama_models_async():
    """æµ‹è¯• 3: ä½¿ç”¨ AsyncClient å¼‚æ­¥è·å–æ¨¡å‹åˆ—è¡¨"""
    logger.info("=" * 60)
    logger.info("æµ‹è¯• 3: ä½¿ç”¨ AsyncClient å¼‚æ­¥è·å–æ¨¡å‹åˆ—è¡¨")
    logger.info("=" * 60)
    
    async def async_get_models():
        try:
            base_url = DEFAULT_OLLAMA_BASE_URL
            
            # ä½¿ç”¨ AsyncClient
            from ollama import AsyncClient
            client = AsyncClient(host=base_url)
            data = await client.list()
            
            # æå–æ¨¡å‹åç§°åˆ—è¡¨
            models = []
            if hasattr(data, 'models'):
                models = [model.name for model in data.models]
            elif isinstance(data, dict):
                models = [model.get('name') for model in data.get('models', []) if model.get('name')]
            
            logger.info(f"âœ… å¼‚æ­¥æˆåŠŸè·å– {len(models)} ä¸ª Ollama æ¨¡å‹")
            for i, model in enumerate(models, 1):
                logger.info(f"  {i}. {model}")
            
            assert len(models) > 0, "åº”è¯¥è‡³å°‘æœ‰ä¸€ä¸ª Ollama æ¨¡å‹"
            return models
            
        except Exception as e:
            logger.error(f"âŒ å¼‚æ­¥è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")
            logger.error(f"   è¯·ç¡®ä¿ Ollama æœåŠ¡æ­£åœ¨è¿è¡Œï¼ˆ{base_url}ï¼‰")
            raise
    
    return asyncio.run(async_get_models())


def test_ollama_chat_sync():
    """æµ‹è¯• 4: åŒæ­¥æ–¹å¼è°ƒç”¨æ¨¡å‹å¯¹è¯"""
    logger.info("=" * 60)
    logger.info("æµ‹è¯• 4: åŒæ­¥æ–¹å¼è°ƒç”¨æ¨¡å‹å¯¹è¯")
    logger.info("=" * 60)
    
    try:
        # å…ˆè·å–å¯ç”¨æ¨¡å‹
        models = [m.model for m in ollama.list()]

        if not models:
            logger.warning("âš ï¸ æ²¡æœ‰å¯ç”¨æ¨¡å‹ï¼Œè·³è¿‡å¯¹è¯æµ‹è¯•")
            return None
        
        model_name = models[0]
        logger.info(f"ä½¿ç”¨æ¨¡å‹: {model_name}")
        
        # æµ‹è¯•ç®€å•å¯¹è¯
        message = "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±"
        logger.info(f"å‘é€æ¶ˆæ¯: {message}")
        
        response = ollama.chat(
            model=model_name,
            messages=[
                {
                    'role': 'user',
                    'content': message
                }
            ]
        )
        
        # æå–å›å¤
        reply = response.get('message', {}).get('content', '') if isinstance(response, dict) else ''
        if not reply and hasattr(response, 'message'):
            reply = response.message.content if hasattr(response.message, 'content') else str(response.message)
        
        logger.info(f"âœ… æ”¶åˆ°å›å¤: {len(reply)} å­—ç¬¦")
        logger.info(f"å›å¤å†…å®¹: {reply[:200]}...")
        
        assert len(reply) > 0, "åº”è¯¥æ”¶åˆ°å›å¤"
        return reply
        
    except Exception as e:
        logger.error(f"âŒ åŒæ­¥å¯¹è¯æµ‹è¯•å¤±è´¥: {e}")
        logger.error(f"   è¯·ç¡®ä¿ Ollama æœåŠ¡æ­£åœ¨è¿è¡Œå¹¶ä¸”æ¨¡å‹å·²ä¸‹è½½")
        raise


async def test_ollama_chat_async():
    """æµ‹è¯• 5: å¼‚æ­¥æ–¹å¼è°ƒç”¨æ¨¡å‹å¯¹è¯"""
    logger.info("=" * 60)
    logger.info("æµ‹è¯• 5: å¼‚æ­¥æ–¹å¼è°ƒç”¨æ¨¡å‹å¯¹è¯")
    logger.info("=" * 60)
    
    try:
        from ollama import AsyncClient
        
        # å…ˆè·å–å¯ç”¨æ¨¡å‹
        client = AsyncClient(host=DEFAULT_OLLAMA_BASE_URL)
        data = await client.list()
        
        models = []
        if hasattr(data, 'models') and len(data.models) > 0:
            models = [model.name for model in data.models]
        elif isinstance(data, dict) and data.get('models'):
            models = [model.get('name') for model in data.get('models', []) if model.get('name')]
        
        if not models:
            logger.warning("âš ï¸ æ²¡æœ‰å¯ç”¨æ¨¡å‹ï¼Œè·³è¿‡å¯¹è¯æµ‹è¯•")
            return None
        
        model_name = models[0]
        logger.info(f"ä½¿ç”¨æ¨¡å‹: {model_name}")
        
        # æµ‹è¯•ç®€å•å¯¹è¯
        message = "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±"
        logger.info(f"å‘é€æ¶ˆæ¯: {message}")
        
        response = await client.chat(
            model=model_name,
            messages=[
                {
                    'role': 'user',
                    'content': message
                }
            ]
        )
        
        # æå–å›å¤
        reply = response.get('message', {}).get('content', '') if isinstance(response, dict) else ''
        if not reply and hasattr(response, 'message'):
            reply = response.message.content if hasattr(response.message, 'content') else str(response.message)
        
        logger.info(f"âœ… å¼‚æ­¥æ”¶åˆ°å›å¤: {len(reply)} å­—ç¬¦")
        logger.info(f"å›å¤å†…å®¹: {reply[:200]}...")
        
        assert len(reply) > 0, "åº”è¯¥æ”¶åˆ°å›å¤"
        return reply
        
    except Exception as e:
        logger.error(f"âŒ å¼‚æ­¥å¯¹è¯æµ‹è¯•å¤±è´¥: {e}")
        logger.error(f"   è¯·ç¡®ä¿ Ollama æœåŠ¡æ­£åœ¨è¿è¡Œå¹¶ä¸”æ¨¡å‹å·²ä¸‹è½½")
        raise


async def test_ollama_chat_stream():
    """æµ‹è¯• 6: æµå¼å¯¹è¯ï¼ˆå¼‚æ­¥ï¼‰"""
    logger.info("=" * 60)
    logger.info("æµ‹è¯• 6: æµå¼å¯¹è¯ï¼ˆå¼‚æ­¥ï¼‰")
    logger.info("=" * 60)
    
    try:
        from ollama import AsyncClient
        
        # å…ˆè·å–å¯ç”¨æ¨¡å‹
        client = AsyncClient(host=DEFAULT_OLLAMA_BASE_URL)
        data = await client.list()
        
        models = []
        if hasattr(data, 'models') and len(data.models) > 0:
            models = [model.name for model in data.models]
        elif isinstance(data, dict) and data.get('models'):
            models = [model.get('name') for model in data.get('models', []) if model.get('name')]
        
        if not models:
            logger.warning("âš ï¸ æ²¡æœ‰å¯ç”¨æ¨¡å‹ï¼Œè·³è¿‡æµå¼å¯¹è¯æµ‹è¯•")
            return None
        
        model_name = models[0]
        logger.info(f"ä½¿ç”¨æ¨¡å‹: {model_name}")
        
        # æµ‹è¯•æµå¼å¯¹è¯
        message = "è¯·ç®€å•ä»‹ç»ä¸€ä¸‹äººå·¥æ™ºèƒ½"
        logger.info(f"å‘é€æ¶ˆæ¯: {message}")
        logger.info("æ¥æ”¶æµå¼å›å¤:")
        logger.info("-" * 60)
        
        content_parts = []
        async for chunk in await client.chat(
            model=model_name,
            messages=[
                {
                    'role': 'user',
                    'content': message
                }
            ],
            stream=True
        ):
            # æå–å†…å®¹
            content = ''
            if isinstance(chunk, dict):
                content = chunk.get('message', {}).get('content', '')
            elif hasattr(chunk, 'message'):
                content = chunk.message.content if hasattr(chunk.message, 'content') else str(chunk.message)
            
            if content:
                content_parts.append(content)
                print(content, end='', flush=True)
        
        print()  # æ¢è¡Œ
        logger.info("-" * 60)
        
        full_content = ''.join(content_parts)
        logger.info(f"âœ… æµå¼æ¥æ”¶å®Œæˆï¼Œå…± {len(full_content)} å­—ç¬¦")
        logger.info(f"å®Œæ•´å†…å®¹é¢„è§ˆ: {full_content[:200]}...")
        
        assert len(full_content) > 0, "åº”è¯¥æ”¶åˆ°å›å¤"
        return full_content
        
    except Exception as e:
        logger.error(f"âŒ æµå¼å¯¹è¯æµ‹è¯•å¤±è´¥: {e}")
        logger.error(f"   è¯·ç¡®ä¿ Ollama æœåŠ¡æ­£åœ¨è¿è¡Œå¹¶ä¸”æ¨¡å‹å·²ä¸‹è½½")
        raise


def test_ollama_error_handling_invalid_model():
    """æµ‹è¯• 7: é”™è¯¯å¤„ç† - ä¸å­˜åœ¨çš„æ¨¡å‹"""
    logger.info("=" * 60)
    logger.info("æµ‹è¯• 7: é”™è¯¯å¤„ç† - ä¸å­˜åœ¨çš„æ¨¡å‹")
    logger.info("=" * 60)
    
    try:
        invalid_model = "non-existent-model-12345-does-not-exist"
        logger.info(f"å°è¯•ä½¿ç”¨ä¸å­˜åœ¨çš„æ¨¡å‹: {invalid_model}")
        
        response = ollama.chat(
            model=invalid_model,
            messages=[
                {
                    'role': 'user',
                    'content': "ä½ å¥½"
                }
            ]
        )
        
        logger.warning("âš ï¸ æœªæŠ›å‡ºé¢„æœŸå¼‚å¸¸ï¼Œæ¨¡å‹å¯èƒ½è¢«è‡ªåŠ¨ä¸‹è½½æˆ–è¿”å›äº†å“åº”")
        logger.info(f"å“åº”: {response}")
        
    except Exception as e:
        error_type = type(e).__name__
        error_str = str(e)
        
        logger.info(f"âœ… æ­£ç¡®æ•è·é”™è¯¯: {error_type}: {error_str}")
        
        # æ£€æŸ¥é”™è¯¯ç±»å‹
        if "ResponseError" in error_type or "status code" in error_str.lower():
            logger.info(f"   é”™è¯¯ç±»å‹: HTTP å“åº”é”™è¯¯")
            # å°è¯•æå–çŠ¶æ€ç 
            import re
            match = re.search(r'status code[:\s]+(\d+)', error_str)
            if match:
                status_code = match.group(1)
                logger.info(f"   çŠ¶æ€ç : {status_code}")
        elif "not found" in error_str.lower() or "ä¸å­˜åœ¨" in error_str.lower():
            logger.info(f"   é”™è¯¯ç±»å‹: æ¨¡å‹ä¸å­˜åœ¨")
        else:
            logger.info(f"   é”™è¯¯ç±»å‹: {error_type}")


def test_ollama_error_handling_invalid_host():
    """æµ‹è¯• 8: é”™è¯¯å¤„ç† - æ— æ•ˆçš„ä¸»æœºåœ°å€"""
    logger.info("=" * 60)
    logger.info("æµ‹è¯• 8: é”™è¯¯å¤„ç† - æ— æ•ˆçš„ä¸»æœºåœ°å€")
    logger.info("=" * 60)
    
    try:
        invalid_host = "http://127.0.0.1:99999"  # ä¸å­˜åœ¨çš„ç«¯å£
        logger.info(f"å°è¯•è¿æ¥åˆ°æ— æ•ˆåœ°å€: {invalid_host}")
        
        client = ollama.Client(host=invalid_host)
        data = client.list()
        
        logger.warning("âš ï¸ æœªæŠ›å‡ºé¢„æœŸå¼‚å¸¸")
        
    except Exception as e:
        error_type = type(e).__name__
        error_str = str(e)
        
        logger.info(f"âœ… æ­£ç¡®æ•è·é”™è¯¯: {error_type}: {error_str}")
        
        # æ£€æŸ¥é”™è¯¯ç±»å‹
        if "connection" in error_str.lower() or "connect" in error_str.lower():
            logger.info(f"   é”™è¯¯ç±»å‹: è¿æ¥é”™è¯¯")
        elif "ResponseError" in error_type:
            logger.info(f"   é”™è¯¯ç±»å‹: HTTP å“åº”é”™è¯¯")
        else:
            logger.info(f"   é”™è¯¯ç±»å‹: {error_type}")


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    logger.info("")
    logger.info("ğŸš€ å¼€å§‹è¿è¡Œ Ollama ç‹¬ç«‹åŠŸèƒ½æµ‹è¯•...")
    logger.info("")
    
    results = {
        'passed': 0,
        'failed': 0,
        'skipped': 0
    }
    
    # æµ‹è¯• 1: è·å–æ¨¡å‹åˆ—è¡¨ï¼ˆç›´æ¥ï¼‰
    try:
        test_get_ollama_models_direct()
        results['passed'] += 1
        logger.info("")
    except Exception as e:
        results['failed'] += 1
        logger.error(f"âŒ æµ‹è¯• 1 å¤±è´¥: {e}")
        logger.info("")
    
    # æµ‹è¯• 2: è·å–æ¨¡å‹åˆ—è¡¨ï¼ˆClientï¼‰
    try:
        test_get_ollama_models_with_client()
        results['passed'] += 1
        logger.info("")
    except Exception as e:
        results['failed'] += 1
        logger.error(f"âŒ æµ‹è¯• 2 å¤±è´¥: {e}")
        logger.info("")
    
    # æµ‹è¯• 3: å¼‚æ­¥è·å–æ¨¡å‹åˆ—è¡¨
    try:
        test_get_ollama_models_async()
        results['passed'] += 1
        logger.info("")
    except Exception as e:
        results['failed'] += 1
        logger.error(f"âŒ æµ‹è¯• 3 å¤±è´¥: {e}")
        logger.info("")
    
    # æµ‹è¯• 4: åŒæ­¥å¯¹è¯
    try:
        test_ollama_chat_sync()
        results['passed'] += 1
        logger.info("")
    except Exception as e:
        results['failed'] += 1
        logger.error(f"âŒ æµ‹è¯• 4 å¤±è´¥: {e}")
        logger.info("")
    
    # æµ‹è¯• 5: å¼‚æ­¥å¯¹è¯
    try:
        asyncio.run(test_ollama_chat_async())
        results['passed'] += 1
        logger.info("")
    except Exception as e:
        results['failed'] += 1
        logger.error(f"âŒ æµ‹è¯• 5 å¤±è´¥: {e}")
        logger.info("")
    
    # æµ‹è¯• 6: æµå¼å¯¹è¯
    try:
        asyncio.run(test_ollama_chat_stream())
        results['passed'] += 1
        logger.info("")
    except Exception as e:
        results['failed'] += 1
        logger.error(f"âŒ æµ‹è¯• 6 å¤±è´¥: {e}")
        logger.info("")
    
    # æµ‹è¯• 7: é”™è¯¯å¤„ç† - æ— æ•ˆæ¨¡å‹
    try:
        test_ollama_error_handling_invalid_model()
        results['passed'] += 1
        logger.info("")
    except Exception as e:
        results['failed'] += 1
        logger.error(f"âŒ æµ‹è¯• 7 å¤±è´¥: {e}")
        logger.info("")
    
    # æµ‹è¯• 8: é”™è¯¯å¤„ç† - æ— æ•ˆä¸»æœº
    try:
        test_ollama_error_handling_invalid_host()
        results['passed'] += 1
        logger.info("")
    except Exception as e:
        results['failed'] += 1
        logger.error(f"âŒ æµ‹è¯• 8 å¤±è´¥: {e}")
        logger.info("")
    
    # è¾“å‡ºæµ‹è¯•æ€»ç»“
    logger.info("=" * 60)
    logger.info("ğŸ“Š æµ‹è¯•æ€»ç»“")
    logger.info("=" * 60)
    logger.info(f"âœ… é€šè¿‡: {results['passed']}")
    logger.info(f"âŒ å¤±è´¥: {results['failed']}")
    logger.info(f"â­ï¸  è·³è¿‡: {results['skipped']}")
    logger.info(f"ğŸ“ˆ æ€»è®¡: {results['passed'] + results['failed'] + results['skipped']}")
    logger.info("")
    
    if results['failed'] == 0:
        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    else:
        logger.warning(f"âš ï¸ æœ‰ {results['failed']} ä¸ªæµ‹è¯•å¤±è´¥")
    
    logger.info("")


if __name__ == "__main__":
    models = [m.model for m in ollama.list().models]